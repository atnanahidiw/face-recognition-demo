{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqLXYmywkqis"
   },
   "source": [
    "# Demo of Face Recognition Inference using Deep Learning\n",
    "Copied from [ONNX ArcFace Example](https://github.com/onnx/models/blob/master/vision/body_analysis/arcface/dependencies/arcface_inference.ipynb) with a slight adjustment\n",
    "\n",
    "**Overview**<br>\n",
    "This notebook can be used for inference on ArcFace ONNX models. The demo shows how to use the trained models to do inference in MXNet.\n",
    "\n",
    "**Models supported**<br>\n",
    "LResNet100E-IR (ResNet100 backend with ArcFace loss)\n",
    "\n",
    "**How To**<br>\n",
    "1. Fill the image URLs you want to compare in `Download input images` section <br>\n",
    "    <img src=\"image1.png\" alt=\"fill-image-url\" width=\"300\" style=\"margin-left:0px\" />\n",
    "<br>\n",
    "2. Click `Kernel` -> `Restart & Run All` to execute all commands in this notebook <br>\n",
    "    <img src=\"image2.png\" alt=\"run-all\" width=\"400\" style=\"margin-left:0px\" />\n",
    "\n",
    "<br>\n",
    "<div style=\"width:550px; color:white; background-color:red; padding:5px; font-size:20px;\"><b>WARNING!<br>The execution may take a long time (20min or more) because we have to download the model first<br>Leave this, do your other job, and check again later</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2mo0CocpVV1"
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tXjekT2kqiy"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from mtcnn_detector import MtcnnDetector\n",
    "from sklearn.preprocessing import normalize\n",
    "from nanti_kita_pelajari_tentang_ini import \\\n",
    "    download_detection_model, get_recognition_model, get_input, get_feature, display_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gezhRMslkqjA"
   },
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDaWryShkqjC"
   },
   "outputs": [],
   "source": [
    "# Determine and set context\n",
    "if len(mx.test_utils.list_gpus())==0:\n",
    "    ctx = mx.cpu()\n",
    "else:\n",
    "    ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "d4iZkmZnkqjL",
    "outputId": "5d843b8d-1203-4375-8532-f06229f07ea2"
   },
   "outputs": [],
   "source": [
    "# Download ONNX model\n",
    "model_dir = 'model-mtcnn'\n",
    "model_path = os.path.join(os.path.dirname('__file__'), model_dir)\n",
    "mx.test_utils.download(\n",
    "    dirname=model_dir, url='https://s3.amazonaws.com/onnx-model-zoo/arcface/resnet100.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLVy75YRkqjS"
   },
   "outputs": [],
   "source": [
    "# Load ONNX model\n",
    "model_name = os.path.join(model_path, 'resnet100.onnx')\n",
    "model = get_recognition_model(ctx , model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxs3W1dXkqjZ"
   },
   "outputs": [],
   "source": [
    "# Configure face detector\n",
    "download_detection_model('https://s3.amazonaws.com/onnx-model-zoo/arcface/mtcnn-model', model_dir)\n",
    "det_threshold = [0.6,0.7,0.8]\n",
    "detector = MtcnnDetector(\n",
    "    model_folder=model_path, ctx=ctx, num_worker=1, accurate_landmark = True, threshold=det_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI0xMIkLkqjg"
   },
   "source": [
    "## Download input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzYvC1Elkqjh"
   },
   "outputs": [],
   "source": [
    "# Please fill this first\n",
    "url1 = \n",
    "url2 = \n",
    "\n",
    "# Download images\n",
    "url = [url1, url2]\n",
    "for u in url:\n",
    "  mx.test_utils.download(u)\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread(url1.split(\"/\")[-1])\n",
    "img2 = cv2.imread(url2.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "wwrMoLXakqjp",
    "outputId": "bd8a54e7-45dc-43a0-92fb-a1ec346db060"
   },
   "outputs": [],
   "source": [
    "# Display first image\n",
    "display_image(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "6dH4wD4Jkqju",
    "outputId": "75f1025e-03c3-464f-f963-446339eb56a3"
   },
   "outputs": [],
   "source": [
    "# Display second image\n",
    "display_image(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66GTfdcnkqj0"
   },
   "source": [
    "## Preprocess images\n",
    "\n",
    "In order to input only face pixels into the network, all input images are passed through a pretrained face detection and alignment model.<br>\n",
    "The output of this model are landmark points and a bounding box corresponding to the face in the image.<br>\n",
    "Using this output, the image is processed using affine transforms to generate the aligned face images which are input to the network.<br>\n",
    "The functions performing this can be checked further in `get_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "JN0VzDoNkqj2",
    "outputId": "29fda373-f6b9-4f91-9feb-31a80734cda1"
   },
   "outputs": [],
   "source": [
    "# Detect face & align in first image\n",
    "%time pre1 = get_input(detector, img1)\n",
    "display_image(np.transpose(pre1, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "RHoWzkdqkqj7",
    "outputId": "96c919b4-0398-416f-c7f2-f81ed5e6a0d5"
   },
   "outputs": [],
   "source": [
    "# Detect face & align in second image\n",
    "%time pre2 = get_input(detector, img2)\n",
    "display_image(np.transpose(pre2, (1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8esG3sFkqkC"
   },
   "source": [
    "## Generate predictions\n",
    "Two face images are passed through the network sequentially to generate embedding vectors for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyZ4wxVJkqkE"
   },
   "outputs": [],
   "source": [
    "# Get embedding of first image & normalize\n",
    "%time out1 = get_feature(model, pre1)\n",
    "out1 = normalize(out1).flatten()\n",
    "\n",
    "# Get embedding of second image & normalize\n",
    "%time out2 = get_feature(model, pre2)\n",
    "out2 = normalize(out2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ezs7r0R2kqkL"
   },
   "outputs": [],
   "source": [
    "# Check normal\n",
    "assert np.sum(np.square(out1)) - 1. < 1e-6\n",
    "assert np.sum(np.square(out2)) - 1. < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8RqGcfbRkqkU",
    "outputId": "3f919436-a754-4a71-89d9-700424b7729b"
   },
   "outputs": [],
   "source": [
    "# Compute [?] distance between embeddings\n",
    "dist = np.sum(np.square(out1-out2))\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "szobISvvqkPB",
    "outputId": "208d5844-1b80-4dd7-92d1-8983b2ea9689"
   },
   "outputs": [],
   "source": [
    "# Compute [?] distance between embeddings\n",
    "dist = np.sum(np.abs(out1-out2))\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wgxzCOcnkqkc",
    "outputId": "f82f39bf-8db1-4f75-d2b0-bf82e0f90be9"
   },
   "outputs": [],
   "source": [
    "# Compute [?] distance between embedddings\n",
    "dist = np.dot(out1, out2.T)\n",
    "print(dist)\n",
    "\n",
    "# Check also https://en.wikipedia.org/wiki/Dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-bT885sLrsmO",
    "outputId": "4179ddcb-b640-4287-e1a8-41aac5a5a799"
   },
   "outputs": [],
   "source": [
    "# Use this if you don't want to convert the distance\n",
    "threshold = np.cos(np.pi/4)\n",
    "\n",
    "if dist > threshold:\n",
    "    print(\"Loh kok mirip? Kembar kah?\")\n",
    "else:\n",
    "    print(\"Ga mirip ah, ngaku-ngaku ya?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above checking is simlar to,\n",
    "threshold = np.pi/4\n",
    "distance = np.arccos(dist)\n",
    "\n",
    "if distance < threshold:\n",
    "    print(\"Loh kok mirip? Kembar kah?\")\n",
    "else:\n",
    "    print(\"Ga mirip ah, ngaku-ngaku ya?\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}